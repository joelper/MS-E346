{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write-up and code for Assignment 6 - Week 3\n",
    "\n",
    "### To do\n",
    "- ~~Model Merton's Portfolio problem as an MDP (write the model in LaTeX)~~\n",
    "- ~~Implement this MDP model in code~~\n",
    "- ~~Try recovering the closed-form solution with a DP algorithm that you implemented previously~~\n",
    "- Model a real-world Portfolio Allocation+Consumption problem as an MDP (including real-world frictions and constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merton's Portfolio Problem\n",
    "### Informal Problem Statement\n",
    "- You will live for $T$ more years, where $T$ is deterministic. \n",
    "- $W_0 > 0 $ is the current wealth $+$ the present value of future income minus debts. \n",
    "- You can invest in $n$ risky assets and 1 riskless asset. \n",
    "- Each asset has a known normal distribution of returns. You are allowed to go long or short any fractional quantities of assets. \n",
    "- Trading is done in continuous time $0 \\leq t < T$, with no transaction costs.\n",
    "- You can consume any fractional amount of wealth at any time.\n",
    "- Dynamic Decision: Optimal Allocation and Consumption at each time with the goal of maximizing the lifetime-aggregated utility of consumption.\n",
    "- Consumtion utility assumed to have Constant Relative Risk-Aversion (CRRA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Notation\n",
    "- The riskless asset is described by: $dR_t = r\\cdot R_t \\cdot dt$\n",
    "- Risky asset $i$ is governed by: $dS_{i,t} = \\mu_i\\cdot S_{i,t}\\cdot dt + \\sigma_i\\cdot S_{i,t} \\cdot dz_{t}$, if we consider $\\mu$ and $\\sigma$ to be vectors and matrices we can write the Geometric Brownian motion in vector form as $dS_{t} = \\mu_i\\cdot S_{t}\\cdot dt + \\sigma\\cdot S_{t} \\cdot dz_{t}$. Where $S_t$ and $dS_t$ are vectors.\n",
    "- $\\mu > r> 0,~ \\sigma >0$ for all $n$ assets.\n",
    "- The wealth at time $t$ is denoted by $W_t > 0$.\n",
    "- Fraction of wealth allocated to risky asset $i$ is denoted by $\\pi_i(t,W_t)$.\n",
    "- Fraction of wealth allocated to riskless asset is denoted by $1 - \\sum_{i=1}^n \\pi_i$.\n",
    "- Wealth consumption denoted by $c(t,W(t)) \\geq 0$\n",
    "- Utility of consumption function $U(x) = \\frac{x^{1-\\gamma}}{1-\\gamma}$ for $0<\\gamma\\neq1$\n",
    "- Utility of consumption function $U(x) = \\log(x)$ for $\\gamma =1$\n",
    "- $\\gamma=$ (constant) Relative Risk-Aversion $\\frac{-x\\cdot U''(x)}{U'(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Decision Process Model\n",
    "We can leverage the framework of an MDP to model Merton's Portolio Problem and thereby use Dynamic Programming to find solutions (more efficient techniques will be covered later). We model this problem using a single risky asset and one riskless asset.\n",
    "- The _State_ is $(t,W_t)$\n",
    "- The _Action_ is $[\\pi_t, c_t]$\n",
    "- The _Reward_ per unit time is $U(c_t)$\n",
    "- The _Return_ is the usual accumulated discounted _Reward_\n",
    "- The goal is to find a _Policy_: $(t, W_t) \\rightarrow [\\pi_t, c_t]$ that maximizes the _Expected Return_\n",
    "- Note: $c_t \\geq 0$, but $\\pi_t$ is unconstrained\n",
    "- The _Transitions_ are governed by the processes mentioned previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for modeling Merton's Portfolio Problem as MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "        \n",
    "def utility_calc(c: float, gamma: float) -> float:\n",
    "    # function to return the utility for a consumption of wealth c and parameter gamma\n",
    "    if np.abs(gamma - 1.0) > 1e-9:\n",
    "        return np.power(c, 1-gamma)/(1 - gamma)\n",
    "    else:\n",
    "        return np.log(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that at each time step you can decide to invest in fraction of 10% in the risky asset (starting from 0 to 1) and you can also consume the wealth in fractions of 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actions = set()\n",
    "for i in np.arange(0,1.1,0.1):\n",
    "    for j in np.arange(0,1.1,0.1):\n",
    "        Actions.add((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = 1.0 # discount rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def trans_and_rew(s: S, a: A, mu: float, sigma: float, r: float, States: Set[S], gamma: float) -> Dict[S, Tuple[float,float]]:\n",
    "    # function that takes in a state and an action and returns a mapping to states with non-zero transition probs,\n",
    "    # and the corresponding trans probability. Assumes normal distribution\n",
    "    # the funciton also returns the utility of the consumption, i.e. the reward\n",
    "    \n",
    "    d = {}\n",
    "    # find the wealth if the stock goes up\n",
    "    s_up = (s[0]+1,np.maximum(int((1 + mu)* a[0] * s[1] + (1 + r)*(1 - a[0]) * s[1] - a[1] * s[1]),0))\n",
    "    # find the wealth if the stock goes down\n",
    "    s_down = (s[0] + 1, np.maximum(int((1 - mu)* a[0] * s[1] + (1 + r)*(1 - a[0]) * s[1] - a[1] * s[1]), 0))\n",
    "                                                                                                       \n",
    "    rew = utility_calc(a[1] * s[1], gamma)\n",
    "    p_down = norm.cdf(0, mu, sigma)\n",
    "    d[s_down] = p_down, rew\n",
    "    d[s_up] = 1 - p_down, rew\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the problem easier, assume that for each combination of action and state we can end up in two different states, one symbolizing an upwards movement for the price of the risky asset, and one state symbolizing a downwards movement. The size of the movement will depend on the amount put in the risky asset, i.e. the action taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem parameters\n",
    "gamma = 0.75\n",
    "mu = 0.23\n",
    "sigma = 0.15\n",
    "r = 0.03\n",
    "\n",
    "States = set()\n",
    "# have an initial wealth of 50\n",
    "S0 = (0,50)\n",
    "States.add(S0)\n",
    "# initialize transition and reward dicts\n",
    "P = {}\n",
    "R = {}\n",
    "\n",
    "new_states = set()\n",
    "new_states.add(S0)\n",
    "# initiate a uniform policy\n",
    "pi = {}\n",
    "for t in range(10):\n",
    "    # create a temporary variable where we store the new states we go to, makes it easier when looping over states\n",
    "    temp_states = set()\n",
    "    for s in new_states:\n",
    "        pi[s] = {}\n",
    "        P[s] = {}\n",
    "        R[s] = {}\n",
    "        for a in sorted(Actions):\n",
    "            # get the transtition probs plus the rewards\n",
    "            d = trans_and_rew(s, a, mu, sigma, r, States, gamma)\n",
    "            # create a uniform policy\n",
    "            pi[s][a] = 1/len(Actions)\n",
    "            P[s][a] = {}\n",
    "            R[s][a] = 0\n",
    "            for sp in d:\n",
    "                P[s][a][sp] = d[sp][0]\n",
    "                R[s][a] += d[sp][1]/2\n",
    "                temp_states.add(sp)\n",
    "                States.add(sp)\n",
    "    new_states = temp_states.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the MDP for this problem\n",
    "mdp = MDP(States, P, Actions, R, disc)\n",
    "# perform value iteration\n",
    "vf, policy = async_value_iter(mdp, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the policy for all states. We can see a trend where early states tend to have a lower consumption rate than later stages. We can also see that earlier states tend to have more aggressive investing in the risky asset. This might be to an unreasonably high expected return ($\\mu = 0.23$) combined with a low standard deviation ($\\sigma = 0.15$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0e1bbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "last_t = 0\n",
    "avg_con = np.zeros((10,1))\n",
    "avg_all = np.zeros((10,1))\n",
    "counter = np.zeros((10,1))\n",
    "for s in sorted(policy):\n",
    "    avg_all[s[0]] += policy[s][0]\n",
    "    avg_con[s[0]] += policy[s][1]\n",
    "    counter[s[0]] += 1  \n",
    "\n",
    "avg_all = np.divide(avg_all, counter)\n",
    "avg_con = np.divide(avg_con, counter)\n",
    "# for i in range(avg_all.shape[0]):\n",
    "#     print(i, avg_all[i], avg_con[i])\n",
    "pl.plot(np.arange(10), avg_all, label='Allocation line')\n",
    "pl.plot(np.arange(10), avg_con, label='Consumption line')\n",
    "pl.xlabel('t')\n",
    "pl.ylabel('Allocation/consumption Rate')\n",
    "pl.legend(loc='center left')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Portfolio Allocation + Consumption Problem\n",
    "In addition to the problem statement above we can introduce several constraints and frictions to make the example closer to a real world scenario. First of all, we can extend the number of risky assets to $n$, with each asset $i$ being guided by a Geometric Brownian motion with parameters $(\\mu_i, \\sigma_i)$. We can also add constraints for how much we are allowed to invest or short in a single asset, in order to diversicate we might say that we cannot invest more than $20\\%$ in each asset. Another aspect to make it closer to the real world is to introduce transaction costs, e.g. reallocating between assets creates a cost that we need to account for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar\n",
    "\n",
    "S = TypeVar('S')\n",
    "A = TypeVar('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Any, Dict, Tuple, Set, Union\n",
    "import numpy as np\n",
    "\n",
    "class MDP(NamedTuple):\n",
    "    States: Set[S]\n",
    "    # the transitions depend on s, a, and s'\n",
    "    # mapping from a state to a mapping of an action to a mapping of a state to a float (probability)\n",
    "    P: Dict[S, Dict[A, Dict[S, float]]]\n",
    "    Actions: A\n",
    "    # reward is a function of the current state,  and the action\n",
    "    R: Union[Dict[S, Dict[A, float]], Dict[S, Dict[A, Dict[S, float]]]]\n",
    "    gamma: float\n",
    "\n",
    "        \n",
    "class Policy(NamedTuple):\n",
    "    # state to action to a probability\n",
    "    pi: Dict[S, Dict[A, float]]\n",
    "        \n",
    "\n",
    "class state_value_function(NamedTuple):\n",
    "    vf: Dict[S,  float]\n",
    "        \n",
    "        \n",
    "class action_value_function(NamedTuple):\n",
    "    vf: Dict[S, Dict[A, float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_value_iter(mdp: MDP, n_iter: int) -> state_value_function:\n",
    "    # implementation of value iteration, the code is very similar to that of policy iteration\n",
    "    # the difference is what kind of information we store\n",
    "    v = {s: 0. for s in mdp.States}\n",
    "    pi = {s: None for s in mdp.P}\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # do asynchronous value iteration\n",
    "        for s in mdp.P:\n",
    "            # variable to store the best value when looping over the actions\n",
    "            best_value = -1000000\n",
    "            best_a = None\n",
    "            for a in mdp.P[s]:\n",
    "                # variable for storing the value for action a\n",
    "                value = mdp.R[s][a]\n",
    "                for sp in mdp.P[s][a]:\n",
    "                    value += mdp.gamma * mdp.P[s][a][sp] * v[sp]\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_a = a\n",
    "            # store the best value\n",
    "            v[s] = best_value\n",
    "            pi[s] = best_a\n",
    "    return v, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(mdp: MDP, policy: Policy, n_iter: int) -> state_value_function:\n",
    "    # implementation of policy evaluation\n",
    "    # asynchrounous version\n",
    "    vf = {s: 0. for s in mdp.States}\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        for s in mdp.P:\n",
    "            vf[s] = 0\n",
    "            for a in mdp.P[s]:\n",
    "                vf[s] += policy[s][a]*mdp.R[s][a]\n",
    "                for sp in mdp.P[s][a]:\n",
    "                    vf[s] += policy[s][a]*mdp.gamma*mdp.P[s][a][sp]*vf[sp]\n",
    "\n",
    "    return vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iter(mdp: MDP, policy: Policy, n_iter: int) -> Policy:\n",
    "    for i in range(n_iter):\n",
    "        new_policy = policy\n",
    "        v = policy_eval(mdp, policy, n_iter)\n",
    "        for s in mdp.P:\n",
    "            best_value = -1000000\n",
    "            best_a: A\n",
    "            for a in mdp.P[s]:\n",
    "                # reinitialize the new policy\n",
    "                new_policy[s][a] = 0.\n",
    "                value = mdp.R[s][a]\n",
    "                for sp in mdp.P[s][a]:\n",
    "                    value += mdp.gamma*mdp.P[s][a][sp]*v[sp]\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_a = a\n",
    "            # make the policy deterministic\n",
    "            new_policy[s][best_a] = 1.0\n",
    "                    \n",
    "        policy = new_policy\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
