{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write-up and code for Feb 13\n",
    "\n",
    "## To Do\n",
    "- Implement Forward-View TD(Lambda) algorithm for Value Function Prediction\n",
    "- Implement Backward View TD(Lambda), i.e., Eligibility Traces algorithm for Value Function Prediction\n",
    "- Implement these algorithms as offline or online algorithms (offline means updates happen only after a full simulation trace, online means updates happen at every time step)\n",
    "- Test these algorithms on some example MDPs, compare them versus DP Policy Evaluation, and plot their accuracy as a function of Lambda\n",
    "- Prove that Offline Forward-View TD(Lambda) and Offline Backward View TD(Lambda) are equivalent. We covered the proof of Lambda = 1 in class. Do the proof for arbitrary Lambda (similar telescoping argument as done in class) for the case where a state appears only once in an episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward View TD($\\lambda$) for Value Function Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1f6b55492299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg_lambd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mforward_view_TD_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMDP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# implementation of forward view TD(lambda) as it is outlined in the lecture slides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Policy' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from modules.MDP import V, Policy\n",
    "from modules.state_action_vars import S, A\n",
    "import numpy as np\n",
    "\n",
    "def n_step_return(return_series: List[float], state_series: List[S], gamma: float, n: int, vf: V) -> np.ndarray:\n",
    "    # returns all the n-step returns from 1 up to n\n",
    "    g_n = np.zeros((n,1))\n",
    "    \n",
    "    for i in range(n):\n",
    "        g_n[i:] += np.power(gamma, i) * return_series[i]\n",
    "        g_n[i] += np.power(gamma, i+1) * vf[state_series[i]]\n",
    "        \n",
    "    return g_n\n",
    "\n",
    "\n",
    "def sum_n_step_return(g_n: np.ndarray, lambd: float) -> float:\n",
    "    # take in all the n-step returns and return the lambda summation form the slides\n",
    "    g_lambda = 0\n",
    "    for j, g in enumerate(g_n):\n",
    "        g_lambda += np.power(lambd, j) * g\n",
    "        \n",
    "    return (1-lambd)*g_lambd\n",
    "\n",
    "def forward_view_TD_lambda(policy: Policy, mdp: MDP, lambd: float, num_epi: int, num_steps: int) -> V:\n",
    "    # implementation of forward view TD(lambda) as it is outlined in the lecture slides\n",
    "    v = {}\n",
    "    gamma = mdp.gamma\n",
    "    for s in mdp.States:\n",
    "        v[s] = 0\n",
    "\n",
    "    for i in range(num_epi):\n",
    "        # generate an episode\n",
    "        s_list, a_list, r_list = generate_path(policy, mdp, num_steps)\n",
    "\n",
    "        for j in range(num_steps):\n",
    "            g_n = n_step_return(r_list[j:], s_list[j:], gamma, num_steps, v)\n",
    "            g_lambd = sum_n_step_return(g_n, lambd)\n",
    "            v[s_list[j]] += alpha * (g_lambd - v[s_list[j]])\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
